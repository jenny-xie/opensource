#+TITLE: propositum | =WINDOWS=
#+PROPERTY: header-args :tangle yes
#+OPTIONS: prop:t

[[https://img.shields.io/github/tag/xeijin/propositum.svg?label=release&style=flat-square]] [[https://ci.appveyor.com/project/xeijin/propositum][https://img.shields.io/appveyor/ci/xeijin/propositum.svg?style=flat-square&logo=appveyor&label=build]] [[https://img.shields.io/badge/license-GPLv3-red.svg?style=flat-square]]


#+BEGIN_QUOTE
A collection of free and open-source, portable tools to facilitate task & information management, automation, data manipulation and analytics.
#+END_QUOTE


* Usage

Installation via the [[https://github.com/xeijin/propositum/releases][Releases]] for the latest binary distribution. Unzip, then ensure you run
the [[Finish]] script.

The next few sections (and this repo) are dedicated to the Literate documentation of the
orchestration script which installs the various components.

#+BEGIN_SRC powershell :exports code
### --- NOTE: If you are reading from the PS1 script you will find documentation sparse, --- ###
### --- this script is accompanied by an org-mode file used to literately generate it.   --- ###
### --- Please see https://github.com/xeijin/propositum for the accompanying README.org  --- ###
#+END_SRC

* Define

Some background on the literate functions used, as well as the tables used to maintain the user-defined [[Components]] and [[Variables]]

** Literate Functions

The list of [[Components]] and their attributes, as well as user-defined [[Variables]] are both maintained in an [[https://orgmode.org/manual/Tables.html][org-mode tables]]. Using [[https://orgmode.org/worg/org-contrib/babel/][org-babel]] and some elisp the contents of these tables are actually executed by PowerShell for use in scripts.

This makes it easier to add new components and variables, as well as modify the existing attributes of these items. It also helps us segregate user-defined inputs from functions, making debugging easier and our code (hopefully) cleaner.

*** Require elisp dependencies
:PROPERTIES:
:ID:       1124209E-CC37-405E-80A0-9466D7FA0FF9
:END:

First, let's ensure we get any required elisp dependencies

#+BEGIN_SRC elisp :exports both
  (require 'org)
  ;(require 'json)
#+END_SRC

*** Import from CSV
:PROPERTIES:
:ID:       BA24D132-E2E5-4603-B856-E804B744B5FE
:END:

Now define an org-babel source code block to /import/ variables from an existing =CSV= file, into an org-mode table. It takes a single argument, the path to the =CSV= file as a string.

#+NAME: org-babel-tbl-import-csv
#+BEGIN_SRC elisp :results value table :exports code :var csv-path=""
  (with-temp-buffer
    (org-table-import csv-path nil) ;; MEMO on `nil' arg is in the footnotes.
    (setq LST (org-table-to-lisp))
    ;; comment out or cut below one line if you don't have column names in CSV file.
    (append (list (car LST)) '(hline) (cdr (org-table-to-lisp))))
#+END_SRC

*** Export to CSV
:PROPERTIES:
:ID:       FC1EE611-609C-4AB4-9BFC-1B27898BCC88
:END:

We also need to define an org-babel source block to export an org-mode table back to a =CSV=.

It takes two arguments, the path to the =CSV= file, and also a name for the org-mode table it generates. Both should be a =string=.

#+NAME: org-babel-tbl-export-csv
#+BEGIN_SRC elisp :exports code :var csv-path="" tbl-name=""
  (save-excursion
    (org-open-link-from-string (concat "[[" tbl-name "]]"))
    (while (not (org-table-p)) (forward-line))
    (org-table-export csv-path "orgtbl-to-csv"))
#+END_SRC

** Components
:PROPERTIES:
:ID:       741E70D9-49CC-4E90-89B0-8B30F110DB46
:END:
  
Components to be installed are maintained in a org-mode table and csv file which holds the metadata:

  - ~var~ short/variable name for the component
  - ~component~ full name for the component (including link to home page)
  - ~license~ license type and evidence url
  - ~usage~ the intended usage of the componet
  - ~categorisation~ categorisation for assisting with internal sign-offs
  - ~status~ whether a component is enabled or disabled
  - ~service~ the method through which the component is acquired
    - ~github-release~ download as a GitHub release artifact (will take care of finding the Url for the latest release)
    - ~github-clone~ clone directly from GitHub repo
    - ~apache-dir-dl~ download from an apache-style directory/file listing web page (e.g. [[https://ftp.gnu.org/gnu/][GNU Download Page]]) 
    - ~direct-dl~ direct download link (can be redirected url)
  - ~user~ the GitHub user for clone / release artifact download
  - ~repo~ the GitHub repo for clone / release artifact download
  - ~regex~ a regular expression to find the latest version of the file
  - ~dl~ direct download link (also used to store the download link in vairous PowerShell functions)
  - ~source~ the source download link (usually where newest versions of files are placed) -- some logic for handling component name/version folders
  - ~comment~ any other noteworthy information on a component

Let's ensure we're in the script root first

#+BEGIN_SRC powershell
  cd $psScriptRoot
#+END_SRC

Now we use org-babel's =#+CALL:= to import our variables defined in ~components.csv~ using the [[Literate Functions]] we defined earlier.

=IMPORT= =IMPORT= =IMPORT=
#+NAME: components-import
#+CALL: org-babel-tbl-import-csv(csv-path="components.csv")
=IMPORT= =IMPORT= =IMPORT=

Next, within the table, define the environment variables and their desired values

#+NAME: components-tbl
#+RESULTS: components-import
| var        | status   | component                | license    | usage                                                                          | categorisation                                               |
|------------+----------+--------------------------+------------+--------------------------------------------------------------------------------+--------------------------------------------------------------|
| cmder      | enabled  | [[http://cmder.net/][Cmder]]                    | [[https://github.com/cmderdev/cmder#license][MIT]]        | console emulator & cmd replacement                                             | Standalone Tool                                              |
| emacs      | enabled  | [[https://www.gnu.org/software/emacs/][emacs]] & [[https://orgmode.org/][org-mode]]         | [[https://github.com/zklhp/emacs-w64/blob/emacs-25/COPYING][GPL-3.0]]    | task & information management, text editor, IDE, composing documentation       | Loosely Coupled with internal code (e.g. internal REST APIs) |
| doom-emacs | enabled  | [[https://github.com/hlissner/doom-emacs][doom-emacs]]               | [[https://github.com/hlissner/doom-emacs/blob/master/LICENSE][MIT]]        | configuration framework for emacs                                              | Loosely Coupled with internal code (e.g. internal REST APIs) |
| autohotkey | disabled | [[https://autohotkey.com/][AutoHotKey]]               | [[https://github.com/Lexikos/AutoHotkey_L/blob/master/license.txt][GPL-2.0]]    | general Windows automation, expanding commonly used text snippets              | Standalone Tool                                              |
| knime      | disabled | [[https://www.knime.com/knime-analytics-platform][KNIME Analytics Platform]] | [[https://www.knime.com/downloads/full-license][GPL-3.0]]    | data pipelines, transformation, automation & reporting                         | Loosely Coupled with internal code (e.g. internal REST APIs) |
| rawgraphs  | disabled | [[http://rawgraphs.io/][RAWGraphs]]                | [[https://github.com/densitydesign/raw/blob/master/LICENSE][Apache-2.0]] | additional data visualisation options                                          | Standalone Tool                                              |
| winpython  | disabled | [[https://winpython.github.io/][WinPython]]                | [[https://github.com/winpython/winpython/blob/master/LICENSE][MIT]]        | portable python runtime to support Apache Superset & data science applications | Standalone Tool                                              |
| superset   | disabled | [[https://superset.incubator.apache.org/][Apache Superset]]          | [[https://github.com/apache/incubator-superset/blob/master/LICENSE.txt][Apache-2.0]] | data exploration, dashboards & data visualisation                              | Standalone Tool                                              |


Then export to ~components.csv~

=EXPORT= =EXPORT= =EXPORT=
#+NAME: components-export
#+CALL: org-babel-tbl-export-csv(csv-path="components.csv", tbl-name="components-tbl")
=EXPORT= =EXPORT= =EXPORT=

#+RESULTS: components-export
: Export done.

*** COMMENT Import into PowerShell
:PROPERTIES:
:ID:       2D7E58E5-B0A0-45D0-ACAA-A3CB3973C285
:END:

We can now import the ~components.csv~ into PowerShell.

The script below will first examine the ~status~ column, importing only ~enabled~ components, this prevents alot of the issues trying to do this through ~if~'s and ~try{}~ ~catch{}~ 

Next, it removes ~\[\[~ and ~\]\]~ placed around each component var name, used to create the hyperlinks in this document. 

Note the ~;~ appended to the ~-replace~ function, which lets us chain another command (in this case outputting ~$_~ so that we retrieve the whole ~PSCustomObject~ after the trim operation is completed).

 #+BEGIN_SRC powershell
   Try
   {
       $components = Import-CSV "components.csv" | ?{ $_.status -ne "disabled" } | %{ $_.var = $_.var.Trim("[]"); $_}
   }
   Catch
   {
       Throw "Check the CSV file actually exists and is formatted correctly before proceeding."
       $error[0]|format-list -force
   }
 #+END_SRC

** Variables
*** Platform-specific variables & secrets

 Use =#+CALL:= once again to import our variables defined in ~vars-platform.csv~

 =IMPORT= =IMPORT= =IMPORT=
 #+NAME: vars-platform-import
 #+CALL: org-babel-tbl-import-csv(csv-path="vars-platform.csv")
 =IMPORT= =IMPORT= =IMPORT=

 Define the environment variables and their desired values in the table

 - note that for AppVeyor some of these are defined in the UI as secrets, but when we run the script locally we will need to securely collect these from the user
 - Remember *not* to include a ~$~ before the variable name in the =var= column of the table. The ~New-Variable~ command will add this in upon execution
 - Important to specify =assign= or =execute= values, otherwise =iex= can cause undesired behaviour (e.g. trying to evaluate a path that doesn't exist instead of assigning)

To make the table neater, we define a few ofthe repeated commands outside of the
table, as variables.
   
#+BEGIN_SRC powershell
$promptPropositumDrv = if(($result = Read-Host -Prompt "Please provide a letter for the Propositum root drive (default is 'P').") -eq ""){("P").Trim(":")+":"}else{$result.Trim(":")+":"} 
$promptGitHubAPIToken = Read-Host -AsSecureString -Prompt "Please provide your GitHub token." 
$promptSupersetPassword = Read-Host -AsSecureString -Prompt "Please provide a password for the Superset user 'Propositum'."  
#+END_SRC
   
Then populate with the variable names, which will be executed by
=Invoke-Expression= (aka =iex=).

 #+NAME: vars-platform-tbl
 #+RESULTS: vars-platform-import
 | type   | exec    | var                    | appveyor              | local                   | local-gs                | testing                 | comment                                                                       |
 |--------+---------+------------------------+-----------------------+-------------------------+-------------------------+-------------------------+-------------------------------------------------------------------------------|
 | normal | assign  | env:propositumLocation | C:\propositum         | C:\propositum           | H:\propositum           | C:\propositum-test      | The =git clone= location of the propositum repo                               |
 | normal | execute | env:propositumDrv      | $env:propositumDrv    | $promptPropositumDrv    | $promptPropositumDrv    | $promptPropositumDrv    | The drive letter =$propositumLocation= will map to                            |
 | secure | execute | env:githubApiToken     | $env:githubApiToken   | $promptGitHubAPIToken   | $promptGitHubAPIToken   | $promptGitHubAPIToken   | API Token for interaction with GH (not currently used in non-AppVeyor builds) |
 | secure | execute | env:supersetPassword   | $env:supersetPassword | $promptSupersetPassword | $promptSupersetPassword | $promptSupersetPassword | The password for the =propositum= user for the =superset= application         |

 Then export to ~vars-platform.csv~

 =EXPORT= =EXPORT= =EXPORT=
 #+NAME: vars-platform-export
 #+CALL: org-babel-tbl-export-csv(csv-path="vars-platform.csv", tbl-name="vars-platform-tbl")
 =EXPORT= =EXPORT= =EXPORT=

 #+RESULTS: vars-platform-export
 : Export done.
*** Other variables

We need to define a few key paths and other variables which will be referred to regularly throughout the coming scripts, but are not platform specific. 

Let's import these from =vars-other.csv=

=IMPORT= =IMPORT= =IMPORT=
#+NAME: vars-other-import
#+CALL: org-babel-tbl-import-csv(csv-path="vars-other.csv")
=IMPORT= =IMPORT= =IMPORT=

Then lets define them in a simplified table

#+NAME: vars-other-tbl
 #+RESULTS: vars-other-import
 | type    | exec    | var             | value                       | comment                                                        |
 |---------+---------+-----------------+-----------------------------+----------------------------------------------------------------|
 | hashtbl | execute | propositum      | @{}                         | Initialises the hash table                                     |
 | path    | execute | propositum.root | $env:propositumDrv+"\"      | Propositum root folder                                         |
 | path    | execute | propositum.apps | $env:propositumDrv+"\apps"  | Propositum apps folder (scoop root)                            |
 | path    | execute | propositum.home | $env:propositumDrv+"\home"  | Propositum home folder (dotfiles & projects)                   |
 | path    | execute | propositum.font | $env:propositumDrv+"\fonts" | Propositum fonts folder                                        |
 | env-var | assign  | env:HOME        | $propositum.home            | Sets env-var home to propositum home                           |
 | env-var | assign  | env:SCOOP       | $propositum.root            | Sets scoop home to the propositum root (creates 'apps' folder) |

And finally, export the table back to csv

 =EXPORT= =EXPORT= =EXPORT=
 #+NAME: vars-other-export
 #+CALL: org-babel-tbl-export-csv(csv-path="vars-other.csv", tbl-name="vars-other-tbl")
 =EXPORT= =EXPORT= =EXPORT=

 #+RESULTS: vars-other-export
 : Export done.
*** Import into PowerShell
As some of the variables are dependent on other build environment functions this section has been moved: [[Import functions & variables]]
* Prepare
Obtain any required tools, initialise variables & setup the build environment

** Set mode & determine build platform
:PROPERTIES:
:ID:       18FAC438-1875-4EE9-96F2-39EB5D0C1B6E
:END:

Add a variable to allow us to switch to testing / development mode - this will use the variable assignments in the "testing" column when we come to our [[Variables]].

#+BEGIN_SRC powershell
$testing = $false
#+END_SRC

Figure out if the script is being run from a local machine, from gs machine or on appveyor, or if we're testing/debugging

#+NAME: set-build-platform
#+BEGIN_SRC powershell
  $buildPlatform = if ($env:APPVEYOR) {"appveyor"}
  elseif ($testing) {"testing"} # For debugging locally
  elseif ($env:computername -match "NDS.*") {"local-gs"} # Check for NDS
  else {"local"}
#+END_SRC
** Initialise Environment
:PROPERTIES:
:ID:       84C36059-E29F-439D-AF82-732D3146F219
:END:
Ensure the necessary tooling is in place & prepare the build environment.

*** Start in the Script Root
:PROPERTIES:
:ID:       772511DD-7D6F-486F-9F2C-8BC128CDA391
:END:

Make sure we start in the script root to avoid issues with executing in the wrong directory & to ensure we can access any scripts or data structures that we need to import.

#+BEGIN_SRC powershell
  cd $PSScriptRoot
#+END_SRC
*** Console formatting
:PROPERTIES:
:ID:       0372ECBA-729F-4B3D-961D-661B18CAC4C5
:END:

Turn the PowerShell background color to Black to make blue output from commands easier to read

#+BEGIN_SRC powershell
  $Host.UI.RawUI.BackgroundColor = ($bckgrnd = 'Black')
#+END_SRC
*** Helper functions
:PROPERTIES:
:header-args: :tangle propositum-helper-fns.ps1
:END:

Define helper functions to perform repetitive activities

**** COMMENT ~Get-GHLatestReleaseDl~: Get the download link for the latest GitHub release

Takes a component hash table as an input

#+BEGIN_SRC powershell
  function Get-GHLatestReleaseDl ($compValsArr) {
  # Original: https://www.helloitscraig.co.uk/2016/02/download-the-latest-repo.html

  # --- Set the uri for the latest release
  $URI = "https://api.github.com/repos/"+$compValsArr.user+"/"+$compValsArr.repo+"/releases/latest"

  # --- Query the API to get the url of the zip

  # Switch to supported version of TLS protocol (1.2) for Github
  [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12

  # Traverse the 
  $latestRelease = Invoke-RestMethod -Method Get -Uri $URI
  $allReleaseAssets = Invoke-RestMethod -Method Get -URI $latestRelease.assets_url

  # RegEx to isolate the filename (and version number if multiple artifacts)
  $releaseAsset = $allReleaseAssets -match $compValsArr.regex

  # Store a sorted list of download URLs (as if contianing version number we want highest at top)
  $downloadUrl = $releaseAsset.browser_download_url | Sort-Object -Descending

  # Check if the downloadUrl is an array, if true return first array value (i.e. highest ver number)
  If ($downloadUrl -is [array]) {return $downloadUrl[0]}

  # If not array, must be single download url, return as string
  Else {return $downloadUrl}
  }
#+END_SRC
**** COMMENT ~Get-LatestApacheDirDl~: Get the download link for latest direct-dl release (Apache directory listing)

Takes a url to the apache directory, a regex for the file and the component's variable name from the table as inputs.

The function makes some basic attempts to try and dig into subdirectories if it doesn't find the file, primarily based on trying to parse a folder beginning with the component name or version number.

#+BEGIN_SRC powershell
  function Get-LatestApacheDirDl ($directoryUrl, $fileRegex, $componentVarName) {

      $componentRegex = "^" + $componentVarName + ".*$"
      $versionRegex = "^(\d*\.\d+)*\/$|^(\d+)*\/$"

      $regexArr = $componentRegex, $versionRegex

      function Get-SiteAsObject ($uri) {
          # Get the HTML and parse
          return (Invoke-WebRequest $uri)
      }

      function Get-UrlFragWithRegex ($siteData, $regex)
      {
          # Initialise Variable
          #$frag = ""
          # Perform match and assign to variable
          $frag = $siteData.Links.href -match $regex | sort -Descending
          #{$frag = $Matches | sort -Descending} # sort descending to get highest ver number
          # Return first element (highest ver) if multiple matches
          If ($frag -is [array]) {return $frag[0]}
          # Otherwise just return as-is
          Else {return $frag}
      }

      #### Function still needs some work, incorrectly parsing table (i.e. not capturing dates)    
      #    function Get-ApacheDirTable ($directoryUrl) {
      #    $directoryUrl.ParsedHtml.getElementsByTagName("tbody") | ForEach-Object {
      #
      #    $Headers = $null
      #
      #    # Might need to uncomment the following line depending on table being parsed
      #    # And if there is more than one table, need a way to get the right headers for each table
      #    #$Headers = @("IP Address", "Hostname", "HW Address", "Device Type")
      #
      #    # Iterate over each <tr> in this table body
      #    $_.getElementsByTagName("tr") | ForEach-Object {
      #        # Select/get the <td>'s, but just grab the InnerText and make them an array
      #        $OutputRow = $_.getElementsByTagName("td") | Select-Object -ExpandProperty InnerText
      #        # If $Headers not defined, this must be the first row and must contain headers
      #        # Otherwise create an object out of the row by building up a hash and then using it to make an object
      #        # These objects can be piped to a lot of different cmdlets, like Out-GridView, ConvertTo-Csv, Format-Table, etc.
      #        if ($Headers) {
      #            $OutputHash = [ordered]@{}
      #            for($i=0;$i -lt $OutputRow.Count;$i++) {
      #                $OutputHash[$Headers[$i]] = $OutputRow[$i]
      #            }
      #            New-Object psobject -Property $OutputHash
      #        } else {
      #            $Headers = $OutputRow
      #
      #        }
      #    }
      #}
      #}
      ### 

      # Initialise variables for loop
      $site = Get-SiteAsObject $directoryUrl
      $match = ""
      $file = ""

      Do {
          ForEach ($regex in $regexArr) {
              # Check each time if the file can be found in the current dir
              $file = Get-UrlFragWithRegex $site $fileRegex
              if ($file -match $fileRegex) {
                  ### COMMENTED OUT OBJ ROUTINE AS NOT PARSING DATES ###
                  # File found, but let's be extra cautious and isolate those with the latest date
                  #$sitePsObj = Get-ApacheDirTable $site
                  # Then find the latest date & filter the table
                  #$sitePsObj | Where-Object {$_.Name -match $fileRegex}
                  # Break out of the loop and return the full URL
                  ### END PS OBJ ROUTINE ###
                  $directoryUrl = $directoryUrl+$file
                  break
              }
              # Otherwise crawl through the RegEx array attempting to find a directory that matches
              else {
                  $match = Get-UrlFragWithRegex $site $regex
                  $directoryUrl = $directoryUrl+$match
                  # Re-initialize the $site object each time we find a match so that we 'enter' the directory
              $site = Get-SiteAsObject $directoryUrl
                  continue
              }
          }
      }
      Until ($file -match $fileRegex)

      # Finally, return the full download Url
      return $directoryUrl
  }
#+END_SRC
**** COMMENT ~Dl-ToDir~: Binary file download wrapper

Since finding no single download tool satisfactorily met my needs, I decided to create a wrapper for them all (plus a relatively easy way to extend for any I may need in the future)

Usage (from ~Get-Help "Dl-ToDir"~)

#+BEGIN_EXAMPLE powershell
  NAME
  Dl-ToDir

  SYNTAX
  Dl-ToDir [[-backend] {curl | wget | aria2c*}] [[-customFilename] <string>] [[-opts] <string[]>] [-uri] <string> [[-dir] <Object>] [-allowRedirs] [-cdispFilename] [-uriFilename]  
  [<CommonParameters>]
#+END_EXAMPLE

=*= =aria2c= is used as the default backend if none is specified

- *Further Enhancements*
  - [ ] Would be good to get backend mapping from org-mode table (with JSON import/export)
  - [ ] Implement multi-file download, particularly for aria2c which supports concurrent connections (could reduce build time)


#+BEGIN_SRC powershell
  function Dl-ToDir {
      # Define Parameters incl. defaults, types & validation
      Param(
      # Define accepted backends, each needs its own hash table entry in switch
      [ValidateSet("curl", "wget", "aria2c")]
      [string]$backend = "aria2c", # default

      # Convenience switches for common behaviours we might need to toggle
      [switch]$allowRedirs,
      [switch]$cdispFilename,
      [switch]$uriFilename,

      # Allow user to specify customFilename, which will disable other options
      [string]$customFilename,

      # Allow user to pass arbitrary options
      [string[]]$opts,
    
      # Make URI mandatory to avoid hash table init issues later
      [parameter(Mandatory=$true)]
      [string]$uri,

      # Check dir exists before accept
      [ValidateScript({Test-Path $_ -PathType 'Container'})]
      $dir = ($dir+"\") # default to current dir if not provided or add backslash to path
      )

      # Define mapping of common commands for each backend
      switch ($backend)
      {
          "curl"
              {
               $cmdMap = [ordered]@{
                          backend = $backend+".exe"; # append .exe to workaround powershell alias issue...
                          allowRedirs = "-L";
                          cdispFilename = "-J";
                          uriFilename = "-O";
                          customFilename = ("-o '"+$customFilename+"'");
                          progressBar = "-#"; # 'graphical' progress indicator, rather than 'tabular' progress indicator
                          uri = $uri;
                          }
              }

          "wget"
              {
               $cmdMap = [ordered]@{
                          backend = $backend+".exe"; # append .exe to workaround powershell alias issue...
                          allowRedirs = if(-not ($allowRedirs)) {"--max-redirect=0"}; # wget allows redirs by default, so disable if switch is false
                          cdispFilename = "--content-disposition";
                          uriFilename = if(-not ($cdispFilename)) {("-O '"+($uri | Split-Path -Leaf)+"'")}; # Get filename from path only if user doesn't want to try sourcing from Content-Disposition
                          customFilename = ("-O '"+$customFilename+"'");
                          overWrite = "-N"; # Note this will only overwrite if the server file timestamp is newer than the local, for 'true' overwrite use the customFilename option
                          progressBar = "--progress=bar:force:noscroll";
                          uri = $uri;
                          }
              }

          "aria2c"
              {
               $cmdMap = [ordered]@{
                          backend = $backend;
                          allowRedirs = ""; # no effect - aria decides this itself
                          cdispFilename = ""; # no effect - aria decides this itself
                          uriFilename = if(-not ($cdispFilename)) {("--out='"+($uri | Split-Path -Leaf)+"'")}; # Get filename from path only if user doesn't want to try sourcing from Content-Disposition
                          customFilename = ("--out='"+$customFilename+"'");
                          overWrite = "--allow-overwrite=true"; # always overwrite an existing file, since mostly we will be running from build servers which start with a fresh env each time. Also prevents creation of .aria control files.
                          dontResume = "--always-resume=false"; # prevent aria from resuming downloads
                          uri = $uri;
                          }
              }

          default # For an unknown backend
              {
              Throw ("Error: backend '"+$backend+"' not found.")
              }
      }

  ## De-dupe $opts params passed by the user

      # Initialize a new List object to hold the RegEx for de-dupe
      $optDeDupe = New-Object Collections.Generic.List[object]

      # Loop through the keys defined in backend hash table & add to array
      ForEach ($key in $cmdMap.Keys)
          {   
          # Get the associated value for the given arg
          $val = $cmdMap.$key

          # If the $arg has a val, add the RegEx to the list
          if($val) {  
              # Concat regex start/end string tokens & add to list
              $optDeDupe.Add("^"+[string]$val+"$")            
            }
          # Otherwise skip to the next $key
          else {continue}
          }

      # Concat into single Regex with "|" (or) operator
      $optDeDupe = $optDeDupe -join "|"


  ## Construct the download command

      # Initialise the hash table used to construct the download command
      $dlCmd = [ordered]@{}

      # Add in backend mapping
      $dlCmd += $cmdMap
    
      #  Exclude any duplicates from $opts passed by user, then Add to hash table
      $uniqueOpts = $opts | ?{ $_ -notmatch $optDeDupe }
      $dlCmd.Add("opts", $uniqueOpts)
    
      # Disable (remove) other parameters if customFileName is passed by user
      if ($customFilename) {

          $dlCmd.Remove("cdispFilename")
          $dlCmd.Remove("uriFilename")
      }
      # Else remove the customFilename entry copied from the array
      else {$dlCmd.Remove("customFilename")}

      # Get enumerated hashtable, where an given key has a value, then:
      # expand each property to just its value before concat into dl command
      $dlCmd = ($dlCmd.GetEnumerator() | ? Value | Select -ExpandProperty Value) -join " "

  ## Download, get filename & return details

      # If dir isn't the current path, store the current directory location then cd to the path
      # this is primarily to workaround limitations with Curl -O
      if($dir -ne (Get-Location)){
      $origLocation = Get-Location
      Set-Location $dir
      }

  Try {

      # Execute the download (and pipe the output to the console)
      iex $dlCmd | Out-Host

      # If a customFilename was specified, return that as the filename
      if ($customFilename)
      {$fileName = $customFilename}
      # Otherwise get the name of the file added to the download folder *after* the command was run
      else {
      $funcExecTimestamp = (Get-History | Where { $_.CommandLine -contains $MyInvocation.MyCommand } | Sort StartExecutionTime -Descending | Select StartExecutionTime -First 1).StartExecutionTime
      $fileName = Get-ChildItem -Path $propTest | Sort-Object LastWriteTime -Descending | ?{ $_.LastWriteTime -gt $funcExecTimestamp } | Select -First 1}
      }

  Finally {
      # cd back to the original location if it exists
      if($origLocaction) {Set-Location $origLocation}

      # Assemble result array (outside of Try block, to assist with debugging) - includes full path to the file, as well as the command used to initiate the download
      $result = ($dir+"\"+$fileName), ([string]$dlCmd)

      }

    return $result

  }
#+END_SRC

Useful parts of the function that I began writing but later realised I didn't need, in particular traversing using the key paradigm may come in handy one day... the code block is set not to tangle.

#+BEGIN_SRC powershell :exports none
  ### Potentially useful but not currently required ###
  #    # Copy the relevant keys 
  #    ForEach ($key in $cmdMap.Keys)
  #
  #    {        
  #        # Set some initial variables to make things more legible
  #        $value = $cmdMap.$key
  #        $keyIsArg = if($PSBoundParameters.ContainsKey($key)) {$true}
  #        $keyAsVarValue = $PSBoundParameters.$key
  #
  #        # If the key is equal to the name of an argument variable and the argument variable is not empty or false
  #        if ( ($keyIsArg) -and ($keyAsVarValue) ) 
  #            # Then add the key-value pair 
  #            {
  #            $dlCmd.Add($key, $value)
  #            }
  #        }
  #    }
  #
  #    # construct the download command
  #    $dlCmd = (([ordered]@{ # [ordered] to preserve command order when we concat later
  #               backend = $cmdMap.backend; # append .exe to workaround powershell alias issue...
  #               allowRedirs = if($allowRedirs){$cmdMap.allowRedirs};
  #               cdispFilename = if($cdispFilename){$cmdMap.cdispFilename};
  #               uriFilename = if($uriFilename){$cmdMap.uriFilename};
  #               uniqueOpts = $opts | ?{ $_ -notmatch $optExcludeRegex }; # Remove any dupe opts that user passed
  #               uri = $uri;
  #               }).Values | %{ [string]$_ }) -join " " # Get hashtable values, recursively convert to string (to catch opts with an arg) then concat into command
  #
  #    # Loop through arguments passed by user and add to array
  #    ForEach ($arg in $PSBoundParameters.Keys)
  #        {   
      #        # Get the associated value for the given arg
      #        $val = $PSBoundParameters.$arg
      #
      #        # Skip '$opts' vals otherwise it will delete opts during de-dupe
      #        if($arg -eq "opts") {continue}
      #        # If the $arg has a val, add the RegEx to the list
      #        if($val) {  
          #            # Concat regex start/end string tokens & add to list
          #            $optDeDupe.Add("^"+[string]$val+"$")            
          #          }
      #        # Otherwise skip to the next $arg
      #        else {continue}
      #        }
#+END_SRC
**** TODO COMMENT ~Write-InstallStatus~: Write & Log Install Status
#+BEGIN_SRC powershell
  function Write-InstallStatus ($component, $arr, $status, $msg) {
    
      # Set status Write-Host colours & messages
      switch ($status)
      {
          "Disabled"
          {
                  $msg = If ($msg) {$msg} else {" Component is disabled -- check the components table. "}
                  $fgColour = "White"
                  $bgColour = "DarkRed"
              }
          "Failed"
          {
                  $msg = If ($msg) {$msg} else {" Component installation failed -- check error message "}
                  $fgColour = "White"
                  $bgColour = "DarkRed"
              }
          "Succeeded"
          {
                  $msg = If ($msg) {$msg} else {" Component installation succeeded. "}
                  $fgColour = "Green"
                  $bgColour = "DarkGreen"
              }
          default # If no status provided
          {
                  $status = "Unknown"
                  $msg = If ($msg) {$msg} else {" Unable to verify the installation status. "}
                  $fgColour = "Yellow"
                  $bgColour = "DarkYellow"
              }
      }
    
      # Send message to user and include the error message if not 'succeeded'
      if($status -ne "Succeeded")
      {Write-Host ("`n ["+$status+"] "+$component.var+": "+$msg+"`nError:`n"+$Error[0]) -ForegroundColor $fgColour -BackgroundColor $bgColour}
      else
      {Write-Host ("`n ["+$status+"] "+$component.var+": "+$msg) -ForegroundColor $fgColour -BackgroundColor $bgColour}
    
      # Write details into psobj Results Array
      $result = [PSCustomObject]@{
          Component = $component.var
          Status = $status
          Date = Get-Date -Format "ddd dd MMM yyyy h:mm:ss tt"
          Message = $msg
          LastError = if ($status -eq "Failed") {"L: "+$Error[0].InvocationInfo.ScriptLineNumber+" "+$Error[0].Exception}
      }
      $arr += $result
  }
#+END_SRC
**** COMMENT ~Refresh-PathVariable~: Refresh Path Variable

Refresh path variable to reflect any executables added from a given installation

#+BEGIN_SRC powershell
  function Refresh-PathVariable {
      foreach($level in "Machine","User") {
      [Environment]::GetEnvironmentVariables($level).GetEnumerator() | % {
          # For Path variables, append the new values, if they're not already in there
          if($_.Name -match 'Path$') { 
              $_.Value = ($((Get-Content "Env:$($_.Name)") + ";$($_.Value)") -split ';' | Select -unique) -join ';'
          }
          $_
      } | Set-Content -Path { "Env:$($_.Name)" }
  }
  }
#+END_SRC
**** TODO ~Path-CheckOrCreate~: Check for path and optionally create dir or symlink
:PROPERTIES:
:ID:       DA8B2429-3EB2-4784-81B1-F69152B9253A
:END:

Check if a dir exists, and if specified, create the directory (or symlink)

#+BEGIN_SRC powershell
  function Path-CheckOrCreate {

  # Don't make parameters positionally-bound (unless explicitly stated) and make the Default set required with all
  [CmdletBinding(PositionalBinding=$False,DefaultParameterSetName="Default")]

      # Define Parameters incl. defaults, types & validation
      Param(
          # Allow an array of strings (paths)
          [Parameter(Mandatory,ParameterSetName="Default")]
          [Parameter(Mandatory,ParameterSetName="CreateDir")]
          [Parameter(Mandatory,ParameterSetName="CreateSymLink")]
          [string[]]$paths,

          # Parameter sets to allow either/or but not both, of createDir and createSymLink. createSymLink is an array of strings to provide the option of matching with multiple paths.
          [Parameter(ParameterSetName="CreateDir",Mandatory=$false)][switch]$createDir,
          [Parameter(ParameterSetName="CreateSymLink",Mandatory=$false)][string[]]$createSymLink = @() # Default value is an empty array to prevent 'Cannot index into null array'
     )

      # Create Arrs to collect the directories that exist/don't exist
      $existing = @()
      $notExisting = @()
      $existingSymLink = @()
      $notExistingSymLink = @()
      $createdDir = @()
      $createdSymLink = @()

      # Loop through directories in $directory
      for ($i = 0; $i -ne $paths.Length; $i++)
      {

          # If exists, add to existing, else add to not existing
          if (Test-Path $paths[$i]) {$existing += , $paths[$i]}
          else {$notExisting += , $paths[$i]}

          # If any symlinks have been provided, also do a check to see if these exist
          if ( ($createSymLink[$i]) -and (Test-Path $createSymLink[$i]) )
          {$existingSymLink += , $createSymLink[$i]}
          else {$notExistingSymLink += , $createSymLink[$i]}

          # Next, check if valid path
          if (Test-Path -Path $paths[$i] -IsValid)
          {
              # If user wants to create the directory, do so
              if ($createDir)
              {
                  if (mkdir $paths[$i]) {$createdDir += , $paths[$i]}
              }
              # If user wants to create a symbolic link, do so
              elseif ($createSymlink)
              {
              if(New-Item -ItemType SymbolicLink -Value $paths[$i] -Path $createSymLink[$i]) # Use the counter to select the right Symlink value
                  {$createdSymLink += , $createSymLink[$i]}
              }
          }
          else {Throw "An error occurred. Check the path is valid."}

      }

      # Write summary of directory operations to console [Turned off as annoying to see each time the command is run]
      #Write-Host "`n==========`n"
      #Write-Host "`n[Summary of Directory Operations]`n"
      #Write-Host "`nDirectories already exist:`n$existing`n"
      #Write-Host "`nDirectories that do not exist:`n$notExisting`n"
      #Write-Host "`nDirectories created:`n$createdDir`n"
      #Write-Host "`nSymbolic Links created:`n$createdSymLink`n"
      #Write-Host "`n==========`n"
    
      # Create a hash table of arrs, to access a given entry: place e.g. ["existing"] at the end of the expression
      # to get the arr value within add an index ref. e.g. ["existing"][0] for the first value within existing dirs
      $result = [ordered]@{
          existing = $existing
          existingSymLinks = $existingSymLink
          notExisting = $notexisting
          notExistingSymLinks = $notExistingSymLink
          createdDirs = $createdDir
          createdSymLinks = $createdSymLink
      }
    
      # Write results to the console
      Write-Host "`n================================="
      Write-Host "[Summary of Directory Operations]"
      Write-Host "=================================`n"
      Write-Host ($result | Format-Table | Out-String)
    
      return $result

  }
#+END_SRC
**** ~GitHub-CloneRepo~: Clone GitHub repo
:PROPERTIES:
:ID:       165F8517-95D6-47B1-BC20-61E92D0A004B
:END:

#+BEGIN_SRC powershell
  function Github-CloneRepo ($opts, $compValsArr, $cloneDir) {
  Write-Host ("Cloning ... [ "+"~"+$compValsArr.user+"/"+$compValsArr.repo+" ]") -ForegroundColor Yellow -BackgroundColor Black
  $cloneUrl = ("https://github.com/"+$compValsArr.user+"/"+$compValsArr.repo)
  iex "git clone $opts $cloneUrl $cloneDir"
  }
#+END_SRC
*** Import functions & variables
**** Import functions
:PROPERTIES:
:ID:       25BEA543-0DB2-4DE4-B099-34333F24516A
:END:

 Let's import the helper functions we defined earlier. Using the =.= notation means they will be imported with access to the variables in the current script scope.

 #+BEGIN_SRC powershell
   . ./propositum-helper-fns.ps1
 #+END_SRC
**** Import platform-specific variables
:PROPERTIES:
:ID:       538BDD23-6F58-424E-AC99-AB361C7B45E7
:END:

 We can now import ~vars-platform.csv~ we created earlier into PowerShell

 #+NAME: collect-platform-vars
 #+BEGIN_SRC powershell
   Try
   {
       $platformVars = Import-CSV "vars-platform.csv"
   }
   Catch
   {
       Throw "Check the CSV file actually exists and is formatted correctly before proceeding."
       $error[0]|format-list -force
   }
 #+END_SRC

 Finally, set each of the platform variables according to ~$buildPlatform~

 - ~Select~ is used to first narrow the ~PSObject~ to the column containing the variable name, and the column matching our buildPlatform
 - ~iex~ ensures that the value of each variable gets executed upon assignment, rather than being stored as a string
 - the ~if~ statement is used in conjunction with the =exec= column as mentioned earlier to avoid incorrectly executing a value that should be assigned

#+NAME: set-platform-vars
 #+BEGIN_SRC powershell
ForEach ($var in $platformVars | Select "var", $buildPlatform, "exec") { # Narrow to required columns & $buildPlatform
    if ($var.var -like "env:*") { # If variable name contains 'env:'
        if ($var.exec -eq "execute") {Set-Item -Verbose -Path $var.var -Value (iex $var.$buildPlatform)}  # If we need to 'execute'
        else {Set-Item -Verbose -Path $var.var -Value $var.$buildPlatform} # Else just assign
    }
    else { # Logic for non-environment variables
        if ($var.exec -eq "execute") {New-Variable -Verbose $var.var (iex $var.$buildPlatform) -Force}
        else {New-Variable -Verbose $var.var $var.$buildPlatform -Force}
    }
}
 #+END_SRC
**** Import other variables
:PROPERTIES:
:ID:       FE6574FA-0768-4A9E-826A-60EA8F8ECBD7
:END:
     
 Let's import the ~vars-other.csv~ into PowerShell

#+NAME: collect-other-vars
 #+BEGIN_SRC powershell
   Try
   {
       $otherVars = Import-CSV "vars-other.csv"
   }
   Catch
   {
       Throw "Check the CSV file actually exists and is formatted correctly before proceeding."
       $error[0]|format-list -force
   }
 #+END_SRC


=$env:= or environment variables are set in a different way to regular
variables, therefore we need some additional logic to handle those:

#+NAME: set-other-vars
#+BEGIN_SRC powershell
ForEach ($var in $otherVars) {
    if ($var.var -like "env:*") { # If variable name contains 'env:'
        if ($var.exec -eq "execute") {Set-Item -Verbose -Path $var.var -Value (iex $var.value)} # If we need to 'execute'
        else {Set-Item -Verbose -Path $var.var -Value $var.value} # Else just assign
    }
    else { # Logic for non-environment variables
        if ($var.exec -eq "execute") {New-Variable -Verbose $var.var (iex $var.value) -Force} 
        else {New-Variable -Verbose $var.var $var.value -Force}
    }
}
#+END_SRC 

**** TESTING

#+BEGIN_SRC powershell
Write-Host $propositum
 
Write-Host $propositum.home

Write-Host $env:home


Set-Item -Verbose -Path env:HOME -Value $propositum.home
#+END_SRC

*** Clear testing directory
:PROPERTIES:
:ID:       64FA9CC2-4B0E-436D-9EC4-E7E6B2BD50B7
:END:

To save some time, let's also delete the contents of the testing directory when in testing mode. 

We also add an additional condition to ensure that =$propositumLocation= has been set, otherwise we could end up deleting the root drive..

Note there's currently a powershell bug that prevents this from working if any symlinks are contained within the directories.

#+BEGIN_SRC powershell
  if ($testing -and $env:propositumLocation) {Remove-Item ($env:propositumLocation+"\*") -Recurse -Force}
#+END_SRC
*** Map propositum drive letter & create folder structure
:PROPERTIES:
:ID:       6DE0B5D0-189B-44BB-B418-201E8D8BD081
:END:
 
 Mapping the propositum folder to a drive letter creates a short, intuitive path to key directories

 #+NAME: map-propositum-drv
  #+BEGIN_SRC powershell
    subst $env:propositumDrv $env:propositumLocation
  #+END_SRC

  Now let's use the hash table we defined earlier in [[Other variables]], and loop through the paths; creating the directories where they don't already exist

  #+BEGIN_SRC powershell
    $createdDirs = Path-CheckOrCreate -Paths $propositum.values -CreateDir
  #+END_SRC

  Using the hash table of directories, we can now navigate to a given folder in the following manner

  #+BEGIN_SRC powershell
    cd $propositum.root
  #+END_SRC
*** Set TLS / SSL versions
:PROPERTIES:
:ID:       0356A598-F416-4B9E-AD32-DE71E9E0167B
:END:
This stops WebClient and other processes that require a secure connection from complaining if the connection requires a version other than TLS v1.0

#+BEGIN_SRC powershell
  [Net.ServicePointManager]::SecurityProtocol = "Tls12, Tls11, Tls, Ssl3"
#+END_SRC
** Install and configure =scoop=
*** Install =scoop=
:PROPERTIES:
:ID:       AC6E8709-BED1-4C65-9290-1D631C0CA7B0
:END:
    
[[https://scoop.sh][scoop]] is a bit like [[https://chocolatey.org][chocolatey]] but focused more on open source tools, and
importantly, allows you to install apps as self-contained 'units', as well as
creating handy manifests for your own apps / customm installs.

We already set the =$env:SCOOP= earlier in [[Other Variables]] so we can go ahead
and install scoop to that path

#+BEGIN_SRC powershell
  iex (new-object net.webclient).downloadstring('https://get.scoop.sh')
#+END_SRC
*** Add =extras= bucket
:PROPERTIES:
:ID:       E9337FC2-A9DB-4F26-8108-C6C44CC66F85
:END:

Add the =extras= bucket which contains some additional free or open source applications outside of the scope of the =main= scoop repo

#+BEGIN_SRC powershell
  scoop bucket add extras
#+END_SRC
*** Add =propositum= bucket
:PROPERTIES:
:ID:       074C0D8F-11F5-4C22-B992-422EA437C37D
:END:

Add the scoop =propositum= bucket which contains the JSON manifest files for installing and configuring the different propositum components.

#+BEGIN_SRC powershell
  scoop bucket add propositum 'https://github.com/xeijin/propositum-bucket.git'
#+END_SRC
*** COMMENT Add =aria2= for faster downloads
:PROPERTIES:
:ID:       6EAA36AD-4CE2-4520-ABDA-DF591D7873A8
:END:
:LOGBOOK:
- Note taken on [2018-08-18 Sat 21:18] \\
  Disabled as Lunacy was failing to download with =aria2= (likely because it was
  trying to use multiple connections).
:END:

*commented out as aria2 currently breaking some downloads due to multiple connections*

Should be auto-detected and used by =scoop=

#+BEGIN_SRC powershell
scoop install aria2
#+END_SRC
*** COMMENT Ensure =7zip= is available
:PROPERTIES:
:ID:       737F5333-F4D2-4C85-9051-CB54BAF6F1C2
:END:

Required by scoop to extract files, and also required by git.

#+BEGIN_SRC powershell
  # If git isn't installed, install it
  if (-not (Get-Command 7z.exe)) {scoop install 7zip --global}
#+END_SRC
*** COMMENT Ensure =git= is available
:PROPERTIES:
:ID:       ABF852A2-5F36-4892-9804-28614F5ED99F
:END:

Required to clone GitHub repos

#+BEGIN_SRC powershell
  # If git isn't installed, install it
  if (-not (Get-Command git.exe)) {scoop install git --global}
#+END_SRC
** Clone =propositum= repo
:PROPERTIES:
:ID:       7895CDF9-52B1-4040-9FEC-1B4EE178C3A9
:END:

   A number of required or source-controlled artifacts, including fonts, scripts and configuration files are already located in the propositum Repo, let's fetch those first

#+BEGIN_SRC powershell
  # Hash table with necessary details for the clone command
  $propositumRepo = [ordered]@{
      user = "xeijin"
      repo = "propositum"
  }

  # Clone the repo (if not AppVeyor as it is already cloned for us)
  if(-not $buildPlatform -eq "appveyor"){Github-CloneRepo "" $propositumRepo $env:propositumLocation}
#+END_SRC
* Build 

Bring together the different components & create the final build artifact.

** Install components
:PROPERTIES:
:ID:       2B59D992-C445-439D-9C67-54554BBDBF7A
:END:

Use scoop to manage the installation of all components, including any
dependencies as defined in the component's manifest JSON.

Anything suffixed with a =-p= (for =propositum=) indicates a customised
manifest, likely doing something fairly specialised.

Use a powershell array to define the components to install (and for better readability)

#+NAME: propositum-components-list
#+BEGIN_SRC powershell
$propositumScoop = @(
    'cmder',
    'lunacy',
    'autohotkey',
    'miniconda3',
    'imagemagick',
    'knime-p',
    'rawgraphs-p',
    'regfont-p',
    'emacs-p',
    'texteditoranywhere-p',
    'superset-p',
    'pandoc'
)
#+END_SRC

Let the user know which components are being installed

#+BEGIN_SRC powershell
$componentsToInstall = $propositumScoop -join "`r`n=> " | Out-String
Write-Host "`r`nThe following components will be installed:`r`n`r`n=> $componentsToInstall" -ForegroundColor Black -BackgroundColor Yellow
#+END_SRC

And =Invoke-Expression= to call the scoop installer with the array

#+BEGIN_SRC powershell
Invoke-Expression "scoop install $propositumScoop"
#+END_SRC
** Install & setup =doom-emacs=
:PROPERTIES:
:ID:       4BCE227D-7309-4E0E-BF45-F00C0E4BD769
:END:

Save the current path & navigate to the =$propositum.home= folder

#+BEGIN_SRC powershell
Push-Location $propositum.home
#+END_SRC

Clone the =doom-emacs= repo as our =.emacs.d= folder and switch to the =develop= branch (=master= is out-of-date)

#+BEGIN_SRC powershell
git clone https://github.com/hlissner/doom-emacs .emacs.d; cd .emacs.d; git checkout develop
#+END_SRC

Add the =doom-emacs= binaries folder to =path=

#+NAME: doom-bin-to-path
#+BEGIN_SRC powershell
$doomBin = $propositum.home + "\.emacs.d\bin"
$env:Path = $env:Path + ";" + $doomBin
#+END_SRC

Refresh the =path= variable using a custom function

#+BEGIN_SRC powershell
Refresh-PathVariable
#+END_SRC


Then =doom quickstart= to install packages for a basic configuration (at least until my custom one is ready)

#+BEGIN_SRC powershell
doom quickstart
#+END_SRC

Return to the original path

#+BEGIN_SRC powershell
Pop-Location
#+END_SRC

*** TODO Create private doom-config
** Create build artifact
:PROPERTIES:
:ID:       0AC1E5F5-D4EE-40F5-ACF3-D7D6C26DC59E
:END:

Create the 7zip'd build artifact for later deployment to GitHub - this is the file unzipped on systems wich require an 'offline' install (i.e. no access to external package repositories).

We only need to do this if running on AppVeyor.

#+BEGIN_SRC powershell
if ($buildPlatform -eq "appveyor")
{
    echo "Compressing files into release artifact..."

    # iex "7z a -t7z -m0=lzma2:d=1024m -mx=9 -aoa -mfb=64 -md=32m -ms=on C:\propositum\propositum.7z C:\propositum"  # Additional options to increase compression ratio
    iex "7z a -t7z -m0=lzma -mx=9 -mfb=64 -md=32m -ms=on propositum.7z C:\propositum"
}
#+END_SRC
* Deploy

Deploy the latest =propositum= release to GitHub.

** Only attempt to deploy if the ~$buildPlatform~ is AppVeyor
:PROPERTIES:
:ID:       1386CD2A-F620-4C8C-968A-EFD58840D0C4
:END:

#+BEGIN_SRC powershell
  if ($buildPlatform -eq "appveyor") {$deploy = $true}
  else {$deploy = $false}
#+END_SRC
* Upgrade
:PROPERTIES:
:header-args: :tangle propositum-upgrade.ps1
:END:

Upgrade an existing instance of =propositum=

*TODO List*

- [ ] tangles as a separate file =propositum-upgrade.ps1=
- [ ] should include the =propositum-helper-fns.ps1=
- [ ] should be able to run as a local user (not an admin)
- [ ] should be able to take the latest propositum artifact release from GitHub as an input
- [ ] should have a separate function that just updates configs (or perhaps a separate github release that is just the config info? e.g. updated .doom.d config file)
* Finish

General clean-up and post-installation activities.

** Generate post-install script
:PROPERTIES:
:header-args: :tangle propositum-post-install.ps1
:ID:       92FEC991-0504-4E1D-8407-F22D12791562
:END:

These are variables or commands that need to be set again post-installation. Note that we use org-babel's =<<NOWEB>>= syntax here to import the variables from wherever they are defined.

This section has a =:PROPERTIES:= section that tangles to =propositum-post-install.ps1= allowing that file to be included e.g. as a script upon launch of cmder (or just run as a one-off).

#+BEGIN_SRC powershell :noweb yes
<<set-build-platform>>
<<collect-platform-vars>>
<<set-platform-vars>>
<<collect-other-vars>>
<<set-other-vars>>
<<set-scoop-env-var>>
<<map-propositum-drv>>
reg add HKCU\SOFTWARE\Microsoft\Windows\CurrentVersion\Run /f /v "Propositum" /d "subst $propositumDrv $propositumLocation" # Add registry entry to map on startup
<<propositum-components-list>> 
<<doom-bin-to-path>>
iex "scoop cleanup **"; iex "scoop reset **"
#+END_SRC

For completeness, here is a script to remove the reigstry key added for mapping
the propositum drive on startup

#+BEGIN_SRC powershell :tangle propositum-remove-drv-startup.ps1
reg delete HKCU\SOFTWARE\Microsoft\Windows\CurrentVersion\Run /f /v "Propositum" # Removes the registry entry to map propositum drive on startup
#+END_SRC
